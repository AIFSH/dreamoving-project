# DreaMoving

[![Paper](https://img.shields.io/badge/cs.CV-Paper-b31b1b?logo=arxiv&logoColor=red)](https://arxiv.org/abs/2312.05107)
[![Project Page](https://img.shields.io/badge/DreaMoving-Website-green?logo=googlechrome&logoColor=green)](https://dreamoving.github.io/dreamoving)
[![Video](https://img.shields.io/badge/YouTube-Video-c4302b?logo=youtube&logoColor=red)](https://github.com/dreamoving/dreamoving-project)

> **DreaMoving: A Human Dance Video Generation Framework based on Diffusion Models**<br>
> [Mengyang Feng](), [Jinlin Liu](), [Kai Yu](), [Yuan Yao](), [Zheng Hui](), [Xiefan Guo](), [Xianhui Lin](), [Haolan Xue](), [Chen Shi](), [Xiaowen Li](), [Aojie Li](), [Miaomiao Cui](), [Peiran Ren](), [Xuansong Xie]()<br>
> Alibaba Group

<strong>TL;DR</strong>: <strong>DreaMoving</strong> is a diffusion-based controllable video generation framework to produce high-quality customized human dance videos.

<table border="0" cellspacing="0" cellpadding="0" align="center">
    <tr>
        <td align="center" valign="middle">
            <video id="v0" width="99%" autoplay loop muted controls>
                <source src="assets/videos/teaser/1.mp4" type="video/mp4" />
            </video>
        </td>
        <td align="center" valign="middle">
            <video id="v0" width="99%" autoplay loop muted controls>
                <source src="assets/videos/teaser/2.mp4" type="video/mp4" />
            </video>
        </td>
        <td align="center" valign="middle">
            <video id="v0" width="99%" autoplay loop muted controls>
                <source src="assets/videos/teaser/3.mp4" type="video/mp4" />
            </video>
        </td>
        <td align="center" valign="middle">
            <video id="v0" width="99%" autoplay loop muted controls>
                <source src="assets/videos/teaser/4.mp4" type="video/mp4" />
            </video>
        </td>
        <td align="center" valign="middle">
            <video id="v0" width="99%" autoplay loop muted controls>
                <source src="assets/videos/teaser/5.mp4" type="video/mp4" />
            </video>
        </td>
        <td align="center" valign="middle">
            <video id="v0" width="99%" autoplay loop muted controls>
                <source src="assets/videos/teaser/6.mp4" type="video/mp4" />
            </video>
        </td>
    </tr>
    <tr>
        <td align="center" valign="middle" width="16%">
            <p style="font-size: 14px;" align="center">
                A girl, smiling, standing on a beach next to the ocean, wearing light yellow dress with long sleeves.
            </p>
        </td>
        <td align="center" valign="middle" width="16%">
            <p style="font-size: 14px;" align="center">
                An Asian girl, smiling, dancing in central park, wearing long shirt and long jeans.
            </p>
        </td>
        <td align="center" valign="middle" width="16%">
            <p style="font-size: 14px;" align="center">
                A girl, smiling, in the park with golden leaves in autumn wearing coat with long sleeve.
            </p>
        </td>
        <td align="center" valign="middle" width="16%">
            <p style="font-size: 14px;" align="center">
                A man, dancing in front of Pyramids of Egypt, wearing a suit with a blue tie.
            </p>
        </td>
        <td align="center" valign="middle" width="16%">
            <p style="font-size: 14px;" align="center">
                A girl, smiling, dancing in a French town, wearing long light blue dress.
            </p>
        </td>
        <td align="center" valign="middle" width="16%">
            <p style="font-size: 14px;" align="center">
                A woman, smiling, in Times Square, wearing white clothes and long pants.
            </p>
        </td>
    </tr>
</table>

## Citation

```bibtex
@article{feng2023dreamoving,
    title={DreaMoving: A Human Dance Video Generation Framework based on Diffusion Models},
    author={Mengyang Feng, Jinlin Liu, Kai Yu, Yuan Yao, Zheng Hui, Xiefan Guo, Xianhui Lin, Haolan Xue,
            Chen Shi, Xiaowen Li, Aojie Li, Miaomiao Cui, Peiran Ren, Xuansong Xie},
    journal={arXiv},
    year={2023}
}
```
